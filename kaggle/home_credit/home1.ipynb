{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c06dc40c-0e26-4b47-bab0-a944e0259e62",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/jsaguiar/lightgbm-7th-place-solution/script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ade3b9b-6d91-49b8-87a9-0a9f7d1bc5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc # garbage collection\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from contextlib import contextmanager # decorate\n",
    "import multiprocessing as mp # \n",
    "# 데이터가 너무 큰데 sequential하게 처리하는 것은 너무 오래 걸림\n",
    "# 따라서 병렬적으로 처리해야하고 이를 처리해주는 것이 multiprocessing! (in python)\n",
    "from functools import partial\n",
    "from scipy.stats import kurtosis, iqr, skew\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc95d91c-c6ef-4b5f-bf61-c852d46fab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "## main\n",
    "pd.set_option('display.max_row', 60)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "debug=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29471d87-8456-4fca-b425-0ff0d972394d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## param\n",
    "DATA_DIRECTORY = 'dataset/'\n",
    "SUBMISSION_SUFIX = '_model2_04'\n",
    "NUM_THREADS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e35953e-8e6e-4753-a697-f9b6c0ac0b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터가 너무 많아서 30000개만 본다!\n",
    "num_rows = 30000 if debug else None\n",
    "# df = get_train_test(DATA_DIRECTORY, num_rows = num_rows)\n",
    "# print('Application dataframe shape:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf1294b6-39d4-454b-9c8e-5232cae34a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_train_test(path, num_rows=None):\n",
    "''' Process application_train.csv and application_test.csv and return a pandas dataframe'''\n",
    "path = DATA_DIRECTORY\n",
    "num_rows = num_rows\n",
    "\n",
    "\n",
    "train=pd.read_csv(os.path.join(path, 'application_train.csv'), nrows=num_rows)\n",
    "test=pd.read_csv(os.path.join(path, 'application_test.csv'), nrows=num_rows)\n",
    "df=train.append(test)\n",
    "del train, test; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fc45ce-8050-4e60-a6ff-d9b63aebc01f",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "455809e0-3c16-4c64-9c2d-a0da5fcf7d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning\n",
    "df = df[df['CODE_GENDER'] != 'XNA'] # 4 people with XNA code gender\n",
    "df = df[df['AMT_INCOME_TOTAL'] < 20000000] # Max income in test is 4M; train has a 117M value\n",
    "df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "df['DAYS_LAST_PHONE_CHANGE'].replace(0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bda5daed-c5c2-45fc-84d4-ae0f71461e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag_document features - count and kurtosis\n",
    "docs = [f for f in df.columns if 'FLAG_DOC' in f]\n",
    "df['DOCUMENT_COUNT'] = df[docs].sum(axis=1)\n",
    "df['NEW_DOC_KURT'] = df[docs].kurtosis(axis=1) # 확률 분포가 얼마나 꼬리되어 있는지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c79db6f2-6882-408f-8627-dbf5071bf5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical age - based on target = 1 plot\n",
    "def get_age_label(days_birth):\n",
    "    \"\"\" Return the age group label (int). \"\"\"\n",
    "    age_years = -days_birth / 365\n",
    "    if age_years < 27: return 1\n",
    "    elif age_years < 40: return 2\n",
    "    elif age_years < 50: return 3\n",
    "    elif age_years < 65: return 4\n",
    "    elif age_years < 99: return 5\n",
    "    else: return 0\n",
    "# Continuous -> categorical\n",
    "df['AGE_RANGE'] = df['DAYS_BIRTH'].apply(lambda x: get_age_label(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e20b8b94-67e1-43b6-8740-0223a42c007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New features based on External sources\n",
    "df['EXT_SOURCES_PROD'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_2'] * df['EXT_SOURCE_3']\n",
    "df['EXT_SOURCES_WEIGHTED'] = df.EXT_SOURCE_1 * 2 + df.EXT_SOURCE_2 * 1 + df.EXT_SOURCE_3 * 3\n",
    "\n",
    "np.warnings.filterwarnings('ignore', r'All-NaN (slice|axis) encountered')\n",
    "# eval을 통해 np function 사용 feature 생성\n",
    "for function_name in ['min', 'max', 'mean', 'nanmedian', 'var']:\n",
    "    feature_name = 'EXT_SOURCES_{}'.format(function_name.upper()) \n",
    "    df[feature_name] = eval('np.{}'.format(function_name))(df[['EXT_SOURCE_1','EXT_SOURCE_2', 'EXT_SOURCE_3']], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11cdf776-fbed-4b6e-81da-9e7291003224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit ratios\n",
    "df['CREDIT_TO_ANNUITY_RATIO'] = df['AMT_CREDIT'] / df['AMT_ANNUITY']\n",
    "df['CREDIT_TO_GOODS_RATIO'] = df['AMT_CREDIT'] / df['AMT_GOODS_PRICE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "338b0383-0c30-4054-b43f-2b72ac391397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Income ratios\n",
    "df['ANNUITY_TO_INCOME_RATIO'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "df['CREDIT_TO_INCOME_RATIO'] = df['AMT_CREDIT'] / df['AMT_INCOME_TOTAL']\n",
    "df['INCOME_TO_EMPLOYED_RATIO'] = df['AMT_INCOME_TOTAL'] / df['DAYS_EMPLOYED']\n",
    "df['INCOME_TO_BIRTH_RATIO'] = df['AMT_INCOME_TOTAL'] / df['DAYS_BIRTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e069c0bf-13cf-4cad-be25-75ef79cf6826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time ratios\n",
    "df['EMPLOYED_TO_BIRTH_RATIO'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "df['ID_TO_BIRTH_RATIO'] = df['DAYS_ID_PUBLISH'] / df['DAYS_BIRTH']\n",
    "df['CAR_TO_BIRTH_RATIO'] = df['OWN_CAR_AGE'] / df['DAYS_BIRTH']\n",
    "df['CAR_TO_EMPLOYED_RATIO'] = df['OWN_CAR_AGE'] / df['DAYS_EMPLOYED']\n",
    "df['PHONE_TO_BIRTH_RATIO'] = df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_BIRTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3ce8d40-9531-48ef-b8e0-b70d617ad7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group(df_to_agg, prefix, aggregations, aggregate_by= 'SK_ID_CURR'):\n",
    "    agg_df = df_to_agg.groupby(aggregate_by).agg(aggregations)\n",
    "    agg_df.columns = pd.Index(['{}{}_{}'.format(prefix, e[0], e[1].upper())\n",
    "                               for e in agg_df.columns.tolist()])\n",
    "    return agg_df.reset_index()\n",
    "\n",
    "\n",
    "def group_and_merge(df_to_agg, df_to_merge, prefix, aggregations, aggregate_by= 'SK_ID_CURR'):\n",
    "    agg_df = group(df_to_agg, prefix, aggregations, aggregate_by= aggregate_by)\n",
    "    return df_to_merge.merge(agg_df, how='left', on= aggregate_by)\n",
    "\n",
    "\n",
    "def do_mean(df, group_cols, counted, agg_name):\n",
    "    gp = df[group_cols + [counted]].groupby(group_cols)[counted].mean().reset_index().rename(\n",
    "        columns={counted: agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "\n",
    "def do_median(df, group_cols, counted, agg_name):\n",
    "    gp = df[group_cols + [counted]].groupby(group_cols)[counted].median().reset_index().rename(\n",
    "        columns={counted: agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "\n",
    "def do_std(df, group_cols, counted, agg_name):\n",
    "    gp = df[group_cols + [counted]].groupby(group_cols)[counted].std().reset_index().rename(\n",
    "        columns={counted: agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "\n",
    "def do_sum(df, group_cols, counted, agg_name):\n",
    "    gp = df[group_cols + [counted]].groupby(group_cols)[counted].sum().reset_index().rename(\n",
    "        columns={counted: agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90db93e5-c5c3-4425-98ae-e5365f4e5d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby: Statistics for applications in the same group\n",
    "group = ['ORGANIZATION_TYPE', 'NAME_EDUCATION_TYPE', 'OCCUPATION_TYPE', 'AGE_RANGE', 'CODE_GENDER']\n",
    "df = do_median(df, group, 'EXT_SOURCES_MEAN', 'GROUP_EXT_SOURCES_MEDIAN')\n",
    "df = do_std(df, group, 'EXT_SOURCES_MEAN', 'GROUP_EXT_SOURCES_STD')\n",
    "df = do_mean(df, group, 'AMT_INCOME_TOTAL', 'GROUP_INCOME_MEAN')\n",
    "df = do_std(df, group, 'AMT_INCOME_TOTAL', 'GROUP_INCOME_STD')\n",
    "df = do_mean(df, group, 'CREDIT_TO_ANNUITY_RATIO', 'GROUP_CREDIT_TO_ANNUITY_MEAN')\n",
    "df = do_std(df, group, 'CREDIT_TO_ANNUITY_RATIO', 'GROUP_CREDIT_TO_ANNUITY_STD')\n",
    "df = do_mean(df, group, 'AMT_CREDIT', 'GROUP_CREDIT_MEAN')\n",
    "df = do_mean(df, group, 'AMT_ANNUITY', 'GROUP_ANNUITY_MEAN')\n",
    "df = do_std(df, group, 'AMT_ANNUITY', 'GROUP_ANNUITY_STD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3f4b5c9-ab8e-482d-ac4b-121087cbe955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder(df, categorical_columns=None):\n",
    "    \"\"\"Encode categorical values as integers (0,1,2,3...) with pandas.factorize. \"\"\"\n",
    "    if not categorical_columns:\n",
    "        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    for col in categorical_columns:\n",
    "        df[col], uniques = pd.factorize(df[col])\n",
    "    return df, categorical_columns\n",
    "df, le_encoded_cols = label_encoder(df, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d92470a-20b7-4a11-8e0e-40c448adc1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_application_columns(df):\n",
    "    \"\"\" Drop features based on permutation feature importance. \"\"\"\n",
    "    drop_list = [\n",
    "        'CNT_CHILDREN', 'CNT_FAM_MEMBERS', 'HOUR_APPR_PROCESS_START',\n",
    "        'FLAG_EMP_PHONE', 'FLAG_MOBIL', 'FLAG_CONT_MOBILE', 'FLAG_EMAIL', 'FLAG_PHONE',\n",
    "        'FLAG_OWN_REALTY', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION',\n",
    "        'REG_CITY_NOT_WORK_CITY', 'OBS_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE',\n",
    "        'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_YEAR', \n",
    "        'COMMONAREA_MODE', 'NONLIVINGAREA_MODE', 'ELEVATORS_MODE', 'NONLIVINGAREA_AVG',\n",
    "        'FLOORSMIN_MEDI', 'LANDAREA_MODE', 'NONLIVINGAREA_MEDI', 'LIVINGAPARTMENTS_MODE',\n",
    "        'FLOORSMIN_AVG', 'LANDAREA_AVG', 'FLOORSMIN_MODE', 'LANDAREA_MEDI',\n",
    "        'COMMONAREA_MEDI', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'BASEMENTAREA_AVG',\n",
    "        'BASEMENTAREA_MODE', 'NONLIVINGAPARTMENTS_MEDI', 'BASEMENTAREA_MEDI', \n",
    "        'LIVINGAPARTMENTS_AVG', 'ELEVATORS_AVG', 'YEARS_BUILD_MEDI', 'ENTRANCES_MODE',\n",
    "        'NONLIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'LIVINGAPARTMENTS_MEDI',\n",
    "        'YEARS_BUILD_MODE', 'YEARS_BEGINEXPLUATATION_AVG', 'ELEVATORS_MEDI', 'LIVINGAREA_MEDI',\n",
    "        'YEARS_BEGINEXPLUATATION_MODE', 'NONLIVINGAPARTMENTS_AVG', 'HOUSETYPE_MODE',\n",
    "        'FONDKAPREMONT_MODE', 'EMERGENCYSTATE_MODE'\n",
    "    ]\n",
    "    # Drop most flag document columns\n",
    "    for doc_num in [2,4,5,6,7,9,10,11,12,13,14,15,16,17,19,20,21]:\n",
    "        drop_list.append('FLAG_DOCUMENT_{}'.format(doc_num))\n",
    "    df.drop(drop_list, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = drop_application_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f75932b9-3341-4e7b-9628-6c72a9e939c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bureau_df = get_bureau(DATA_DIRECTORY, num_rows= num_rows)\n",
    "bureau = pd.read_csv(os.path.join(path, 'bureau.csv'), nrows=num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70644fb5-1300-4f8e-b3d5-af147bfdc9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit duration and credit/account end date difference\n",
    "bureau['CREDIT_DURATION'] = - bureau['DAYS_CREDIT'] + bureau['DAYS_CREDIT_ENDDATE']\n",
    "bureau['ENDDATE_DIF'] = bureau['DAYS_CREDIT_ENDDATE'] - bureau['DAYS_ENDDATE_FACT']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b3245ac-a859-43fe-8019-1fb73d19b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit to debt ratio and difference\n",
    "bureau['DEBT_PERCENTAGE'] = bureau['AMT_CREDIT_SUM'] / bureau['AMT_CREDIT_SUM_DEBT']\n",
    "bureau['DEBT_CREDIT_DIFF'] = bureau['AMT_CREDIT_SUM'] - bureau['AMT_CREDIT_SUM_DEBT']\n",
    "bureau['CREDIT_TO_ANNUITY_RATIO'] = bureau['AMT_CREDIT_SUM'] / bureau['AMT_ANNUITY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f5146fd-7992-40f7-9cdd-9ddbc4bf89d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "def one_hot_encoder(df, categorical_columns=None, nan_as_category=True):\n",
    "    \"\"\"Create a new column for each categorical value in categorical columns. \"\"\"\n",
    "    original_columns = list(df.columns)\n",
    "    if not categorical_columns:\n",
    "        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns=categorical_columns, dummy_na=nan_as_category)\n",
    "    categorical_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, categorical_columns\n",
    "\n",
    "\n",
    "bureau, categorical_cols = one_hot_encoder(bureau, nan_as_category=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65f87d2-238e-4dcc-bef1-816ae74a1469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
